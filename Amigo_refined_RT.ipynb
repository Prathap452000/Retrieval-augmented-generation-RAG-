{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cced272-ef2b-401d-b2a1-2b6a1e36482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6724b1-774e-4299-b148-4bae620645e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "import os\n",
    "import pygame\n",
    "from gtts import gTTS\n",
    "from time import sleep\n",
    "import speech_recognition as sr\n",
    "import tempfile\n",
    "import torch\n",
    "import datetime  # New import for date and time\n",
    "import requests  # For accessing location service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd14eb1d-7210-49fd-b283-b2d25eba0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress FutureWarning for tokenization spaces\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.tokenization_utils_base\")\n",
    "# Load the model and tokenizer globally to avoid reloading every time\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da507c7a-c24f-48dc-bdda-1b965d84ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenWeatherMap API key\n",
    "WEATHER_API_KEY = '6375f15162952d140f9908db1d7ffb99'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1a7e0-80a0-4e4d-813d-e11fef63a0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a0419c-50bc-4518-adbf-70111eab3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_speech(mic_index):\n",
    "    recognizer = sr.Recognizer()\n",
    "    recognizer.energy_threshold = 300  # Lower energy threshold for faster detection\n",
    "    mic = sr.Microphone(device_index=mic_index)\n",
    "    \n",
    "    with mic as source:\n",
    "        print(\"Listening for your query...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)  # Optimized ambient noise detection\n",
    "        \n",
    "        try:\n",
    "            # Listen with optimized timeout and phrase time limit\n",
    "            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)  # Reduced timeout and phrase limit\n",
    "\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"Listening timed out, please speak again.\")\n",
    "            return None  # Return None if timeout occurs\n",
    "\n",
    "    try:\n",
    "        user_input = recognizer.recognize_google(audio)\n",
    "        print(f\"User said: {user_input}\")  # Display user input\n",
    "        return user_input\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I could not understand the audio.\")\n",
    "        return None\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Error with the Google Speech Recognition service; {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399f59ce-e574-4af6-8f98-f184a0b0b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_time_date_queries(user_input):\n",
    "    if \"time\" in user_input:\n",
    "        current_time = datetime.datetime.now().strftime(\"%I:%M %p\")\n",
    "        return f\"The current time is {current_time}.\"\n",
    "    elif \"date\" in user_input or \"today\" in user_input:\n",
    "        current_date = datetime.datetime.now().strftime(\"%A, %B %d, %Y\")\n",
    "        return f\"Today is {current_date}.\"\n",
    "    elif \"location\" in user_input or \"where am i\" in user_input:\n",
    "        return get_current_location()  # Fetch current location\n",
    "    elif \"weather\" in user_input or \"weather in my current location\" in user_input:\n",
    "        return get_current_weather()\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2224e08-f418-401b-be7b-d05a1368d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_microphone():\n",
    "    mic_list = sr.Microphone.list_microphone_names()\n",
    "    index = 2\n",
    "    # Removed print statement for microphone selection\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785ba9ca-fe55-43d8-8638-c4002cb8e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_location():\n",
    "    try:\n",
    "        # Using a free IP geolocation service\n",
    "        response = requests.get(\"http://ip-api.com/json\")\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] == 'success':\n",
    "            city = data.get('city', 'unknown city')\n",
    "            region = data.get('regionName', 'unknown region')\n",
    "            country = data.get('country', 'unknown country')\n",
    "            return f\"You are currently in {city}, {region}, {country}.\"\n",
    "        else:\n",
    "            return \"Sorry, I could not determine your location.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching location: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584b523a-924e-4bc9-8249-aa887b23ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather():\n",
    "    location = get_current_location()\n",
    "    if \"in\" in location:\n",
    "        city = location.split(\"in \")[1].split(\",\")[0]\n",
    "        try:\n",
    "            weather_url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={WEATHER_API_KEY}&units=metric\"\n",
    "            response = requests.get(weather_url)\n",
    "            data = response.json()\n",
    "            if data['cod'] == 200:\n",
    "                weather_description = data['weather'][0]['description']\n",
    "                temperature = data['main']['temp']\n",
    "                return f\"The current weather in {city} is {weather_description} with a temperature of {temperature}°C.\"\n",
    "            else:\n",
    "                return \"Sorry, I couldn't get the weather information.\"\n",
    "        except Exception:\n",
    "            return \"Error fetching weather.\"\n",
    "    else:\n",
    "        return \"I couldn't determine the location for weather.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86155d3-0129-48ac-8b54-45e2d6efc0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_response(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio_file:\n",
    "        tts.save(temp_audio_file.name)\n",
    "        temp_file_path = temp_audio_file.name\n",
    "    pygame.mixer.init()\n",
    "    try:\n",
    "        pygame.mixer.music.load(temp_file_path)\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.wait(50)  # Check every 50ms for faster termination\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing audio: {e}\")\n",
    "    finally:\n",
    "        pygame.mixer.quit()\n",
    "        if os.path.exists(temp_file_path):\n",
    "            os.remove(temp_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b35904a0-7db2-427a-8fe1-e332d50fc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    # Check if the user asked for the AI's name\n",
    "    if \"what is your name\" in user_input.lower():\n",
    "        return \"I am Amigo, your all-weather conversational companion, just like the bike that you are riding on.\"\n",
    "    \n",
    "    # Handle time and date queries separately\n",
    "    time_date_response = handle_time_date_queries(user_input)\n",
    "    if time_date_response:\n",
    "        return time_date_response\n",
    "\n",
    "    # Check for factual or current event queries\n",
    "    if any(keyword in user_input.lower() for keyword in [ \"who is\", \"when is\", \"where is\", \"current\", \"today\", \"news\",\"capital\",\"Places\"]):\n",
    "        return \"Thank you for your query, but that's out of my scope of training.\"\n",
    "\n",
    "    # Tokenize user input\n",
    "    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, max_length=50)  # Reduced max length\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Ensure the attention mask is correctly set\n",
    "    if 'attention_mask' not in inputs:\n",
    "        inputs['attention_mask'] = torch.ones_like(inputs['input_ids'])  # Create a default attention mask\n",
    "    \n",
    "    # Generate bot response with reduced max output length\n",
    "    reply_ids = model.generate(inputs['input_ids'], max_length=50, pad_token_id=tokenizer.eos_token_id)  # Reduced response length\n",
    "    \n",
    "    # Decode response with clean-up for tokenization spaces\n",
    "    bot_response = tokenizer.decode(reply_ids[0], skip_special_tokens=True, attention_mask=attention_mask, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    return bot_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1abfacb-140b-4b77-bfc4-4511727f7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_for_wake_word(mic_index):\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=mic_index)\n",
    "\n",
    "    print(\"Waiting for wake word 'Hey Amigo'...\")\n",
    "    while True:\n",
    "        with mic as source:\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.5)  # Faster ambient noise adjustment\n",
    "            audio = recognizer.listen(source)  # Removed timeout for seamless experience\n",
    "            \n",
    "        try:\n",
    "            user_input = recognizer.recognize_google(audio)\n",
    "            print(f\"User said: {user_input}\")\n",
    "            if \"hey amigo\" in user_input.lower():\n",
    "                print(\"Wake word detected!\")  # Display wake word detected immediately\n",
    "                return True  # Wake word detected, start conversation\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Error with the Google Speech Recognition service: {e}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5aab54-62b4-4e64-aca0-0a45e29b97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amigo_conversational_companion():\n",
    "    mic_index = select_microphone()\n",
    "\n",
    "    if listen_for_wake_word(mic_index):\n",
    "        greeting = \"Hi Hello Namaskara, I am Amigo. How can I assist you today?\"\n",
    "        print(f\"Amigo: {greeting}\")\n",
    "        speak_response(greeting)\n",
    "\n",
    "        while True:\n",
    "            user_input = capture_speech(mic_index)\n",
    "            if user_input is None:\n",
    "                continue\n",
    "\n",
    "            if \"exit\" in user_input.lower() or \"goodbye\" in user_input.lower():\n",
    "                farewell_message = \"Goodbye, have a nice day!\"\n",
    "                print(f\"Amigo: {farewell_message}\")\n",
    "                speak_response(farewell_message)\n",
    "                break\n",
    "\n",
    "            bot_response = generate_response(user_input)\n",
    "            print(f\"Amigo: {bot_response}\")\n",
    "            speak_response(bot_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "605bb16a-e627-467f-8f49-36704e5577e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for wake word 'Hey Amigo'...\n",
      "User said: hey Amigo\n",
      "Wake word detected!\n",
      "Amigo: Hi Hello Namaskara, I am Amigo. How can I assist you today?\n",
      "Listening for your query...\n",
      "User said: what is the weather in my current location\n",
      "Amigo: You are currently in Bengaluru, Karnataka, India.\n",
      "Listening for your query...\n",
      "User said: what is the weather in my location\n",
      "Amigo: You are currently in Bengaluru, Karnataka, India.\n",
      "Listening for your query...\n",
      "User said: what is the weather in my place\n",
      "Amigo: The current weather in Bengaluru is scattered clouds with a temperature of 28.54°C.\n",
      "Listening for your query...\n",
      "User said: exit\n",
      "Amigo: Goodbye, have a nice day!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    amigo_conversational_companion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf8780-4288-41b6-a162-9b7074a4e3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
